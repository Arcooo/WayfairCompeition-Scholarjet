{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLOCK 1: IMPORTS\n",
    "\n",
    "# Python Library Imports \n",
    "import pandas as pd  # for Dataframes\n",
    "import numpy as np  # for arrays\n",
    "import matplotlib.pyplot as plt  # for plotting visuals\n",
    "# import operator\n",
    "\n",
    "# import xgboost as xgb  # boosted decision trees\n",
    "# import pandas_ml as pdml\n",
    "\n",
    "# import sklearn  # for machine learning\n",
    "# from sklearn import tree \n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# from sklearn.preprocessing import scale\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler  \n",
    "# from sklearn.metrics import log_loss, accuracy_score\n",
    "# from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz\n",
    "# from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "# from IPython.display import Image\n",
    "\n",
    "# import pickle # persistant objects aka classifier after training\n",
    "\n",
    "# from collections import Counter\n",
    "# from sklearn.datasets import make_classification\n",
    "# import subprocess\n",
    "\n",
    "# from sklearn.datasets import load_svmlight_files\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "# from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BLOCK 2: STYLING And Globals\n",
    "\n",
    "# # Styling\n",
    "# pd.set_option('notebook_repr_html', True)\n",
    "# pd.set_option('max_columns', 50)\n",
    "# # pd.set_option('display.width', 1000)\n",
    "# pd.set_option('max_colwidth', 40)\n",
    "# %matplotlib inline \n",
    "# # pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # for Dataframes\n",
    "import numpy as np  # for arrays\n",
    "import matplotlib.pyplot as plt  # for plotting visuals\n",
    "\n",
    "class Preprocessing():\n",
    "    def __init__(self):\n",
    "        self.df = -1 #main dataframe\n",
    "        \n",
    "        self.log = [] #log of everything list\n",
    "        self.logCount = 0 #what number log count for debugging\n",
    "    \n",
    "    # Imports file into a dataframe:df for class\n",
    "    def dataImport(self, filename, filetype):\n",
    "        s = \"LOG:\" + str(self.logCount)\n",
    "        if (type(self.df) == pd.DataFrame):\n",
    "            s += \" You have already imported FILE\"\n",
    "        else:\n",
    "            s += \" Importing file into a -CLASS Dataframe\"\n",
    "            try:\n",
    "                self.df = pd.read_csv(filename, index_col=0)\n",
    "            except:\n",
    "                s += \" -INPUT FILE EXCEPTION\"\n",
    "                \n",
    "        self.log.append(s)\n",
    "        self.logCount += 1\n",
    "        return(self.log, self.df)\n",
    "    \n",
    "    # 1 Categorical function that returns a list of all the category columns\n",
    "    def categoryFeatures(self, *file):\n",
    "        s = \"LOG:\" + str(self.logCount)\n",
    "        catColList = []\n",
    "        for cat in range(self.df.shape[1]):\n",
    "            if self.df.dtypes[cat] == 'object':\n",
    "                catColList.append(self.df.columns[cat])\n",
    "                \n",
    "        s += \" CategoryFeatures: \" + str(catColList)\n",
    "        self.log.append(s)\n",
    "        self.logCount += 1\n",
    "        return(self.log, self.df, catColList)\n",
    "    \n",
    "    # Categorical function that returns all the counts for each unique category within the category column\n",
    "    def categoryCounts(self, df, catColList, *cmpCols):\n",
    "        s = \"LOG:\" + str(self.logCount)\n",
    "                        \n",
    "        categTotals = [] # list to hold the totals for each unique category with each category column\n",
    "\n",
    "        cmpColLists = [] # a list of lists for the additional comparison columns\n",
    "        for each in cmpCols: # create a list for each additional parameter\n",
    "            cmpColLists.append([])\n",
    "        \n",
    "        for catIndex, cat in enumerate(catColList): # for each category out of the columns\n",
    "            # the general idea is to create a dictionary for each unique, get info, then append it to either categTotals or cmpColLists\n",
    "            categTotalsd = {}\n",
    "            \n",
    "            others = []\n",
    "            for each in cmpCols:\n",
    "                others.append({})\n",
    "            \n",
    "            # For each unique category in the column\n",
    "            # catUniqueIndex = index of each unique category\n",
    "            # uniqueCat = a category within that category column\n",
    "            # e.g \n",
    "            # Category Column, roll_up, has Unique Categories 'retention', 'unmanaged', 'onboarding'\n",
    "            for catUniqueIndex, uniqueCat in enumerate(df[cat].unique()):\n",
    "                categTotalsd[uniqueCat] = df[cat].value_counts()[uniqueCat]  # totals of each uniqueCategory in category columns\n",
    "                \n",
    "                # for each in the list of comparison columns\n",
    "                for i, each in enumerate(cmpCols):\n",
    "                    tempDfBool = (df[each]>0) & (df[cat] == uniqueCat) # boolean df of all the positives\n",
    "                    tempDfCats = df[tempDfBool] # df of just positives \n",
    "                    others[i][uniqueCat] = tempDfCats[each].sum().round(2) # sum of the column row\n",
    "            \n",
    "            #appending for category totals\n",
    "            categTotals.append(cat)\n",
    "            categTotals.append(categTotalsd)    \n",
    "            \n",
    "            #appending for each in list of comparison columns\n",
    "            for i, each in enumerate(cmpCols): \n",
    "                cmpColLists[i].append(cat)\n",
    "                cmpColLists[i].append(others[i])\n",
    "                \n",
    "        s += \" Found counts for: \" + str(catColList) + \"\\n\"\n",
    "        s += \"Found uniques and their counts too\"\n",
    "        self.log.append(s)\n",
    "        self.logCount += 1\n",
    "        return self.log, self.df, categTotals, cmpColLists\n",
    "    \n",
    "    def categoryStats(self, df, categTotals, cmpColLists):\n",
    "        s = \"LOG:\" + str(self.logCount)\n",
    "        assert(len(cmpColLists) >= 2)\n",
    "        \n",
    "        pcntPos = []\n",
    "        avgPrice = []\n",
    "        \n",
    "        for totals, item, item2 in zip(categTotals, cmpColLists[0], cmpColLists[1]):\n",
    "            pcntPosd = {}\n",
    "            avgPriced = {}\n",
    "            if type(item) == dict and type(item2) == dict:\n",
    "                for x in item:\n",
    "                    pcntPosd[x] = item.get(x) / totals.get(x)\n",
    "                    if(item.get(x) == 0):\n",
    "                        avgPriced[x] = 0\n",
    "                    else:\n",
    "                        avgPriced[x] = item2.get(x) / item.get(x)\n",
    "                pcntPos.append(pcntPosd)\n",
    "                avgPrice.append(avgPriced)\n",
    "                \n",
    "        s += \" categoryStats function: %positive for each cat, avgPrice of buy\"\n",
    "        self.log.append(s)\n",
    "        self.logCount += 1        \n",
    "        return self.log, self.df, pcntPos, avgPrice\n",
    "    \n",
    "    def meanDf(self, df, classification, regression):\n",
    "        totalInDf = len(df)\n",
    "        \n",
    "        classi = df[classification] > 0\n",
    "        classi = df[classi]\n",
    "        totalClass = len(classi)\n",
    "\n",
    "        regre = df[regression] > 0\n",
    "        regre = df[regre]\n",
    "        totalRegre = len(regre)\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "def lPrint(objList):\n",
    "    for i, each in enumerate(objList):\n",
    "        print(each)\n",
    "\n",
    "pre = Preprocessing()\n",
    "log, df = pre.dataImport('files/small.csv','csv')\n",
    "log, df, catColList = pre.categoryFeatures()\n",
    "log, df, categTotals, cmpColLists = pre.categoryCounts(df, catColList, 'convert_30', 'revenue_30')\n",
    "log, df, pcntPos, avgPrice = pre.categoryStats(df, categTotals, cmpColLists)\n",
    "pre.meanDf(df, 'convert_30', 'revenue_30')\n",
    "\n",
    "# lPrint(pcntPos)\n",
    "# lPrint( avgPrice)\n",
    "# print(log)\n",
    "# print(cmpColLists)\n",
    "\n",
    "\n",
    "# listPrinter(cmpColLists[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Printer():\n",
    "    def __init__():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Python is great!\n",
      "Look for Geeksforgeeks Python Section\n",
      "Look for Geeksforgeeks Python Section\n"
     ]
    }
   ],
   "source": [
    "def f(): \n",
    "    global s \n",
    "    print('1', s) \n",
    "    s = \"Look for Geeksforgeeks Python Section\"\n",
    "    print(s)  \n",
    "  \n",
    "# Global Scope \n",
    "s = \"Python is great!\" \n",
    "f() \n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # append to lists     \n",
    "#             categTotalsd = sorted(categTotalsd.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
